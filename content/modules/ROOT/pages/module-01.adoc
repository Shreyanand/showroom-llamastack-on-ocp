= Getting Started with Llama Stack

== Exploring the lab
The lab is designed to be interactive and hands-on, allowing you to explore the capabilities of LlamaStack and OpenShift AI in a practical setting. The lab environment is pre-configured with all necessary components, so you can focus on learning and experimentation without worrying about setup or configuration issues.

=== Exploring the nodes
The lab environment consists of multiple nodes but the important ones to observe are the GPU nodes. In the OpenShift web console perform the following steps to view the nodes:

1. In the OpenShift web console, navigate to **Compute** > **Nodes**.
2. Click Roles to filter the nodes by role.
3. Identify the nodes with the role **worker, worker-gpu** are Ready.

image::nodes.png[OpenShift Nodes, width=100%]

=== Accessing OpenShift AI
The OpenShift AI console is accessible via the OpenShift web console. You can log in using the same credentials used to login to the OpenShift environment to access the OpenShift AI.

Locate the OpenShift Route for the OpenShift AI console by performing the following steps:

1. In the OpenShift web console, navigate to **Networking** > **Routes**.
2. Filter the list of routes by specifying the Name **rhods**
3. Click on the URL link to access the OpenShift AI console.
4. Log in using the same credentials used to log in to the OpenShift environment.

=== Model serving
Two models are available for serving in the lab environment:

* Granite 3.2 8B
* Llama 3.2 3B

The image below shows the model serving status in the OpenShift AI console.

image::model-deploys.png[Model Deployments, width=100%]

These models and their status can be viewed in the OpenShift AI console. Perform the following steps to view the models:

1. In the OpenShift AI console, navigate to **Models** > **Model Deployments**.
2. Look for a green check mark next to the model name. This indicates that the model is successfully deployed and ready for use.

The models have already been defined within the Llama Stack configuration so that they are ready to be used by the Workbench.

=== Accessing the Workbench
The Workbench is a collaborative environment that allows you to interact with the Llama Stack instance and interact with various AI tools including MCP.
To access the Workbench, perform the following steps:

1. In the OpenShift AI console, navigate to **Data science projects**
2. Click on the **llama-serve** project
3. Click on the **Workbench** tab
4. Click on the blue **Lab** button which will open a new tab in your browser to the notebook server

You are now ready to start using the Workbench and explore the capabilities of LlamaStack and OpenShift AI. The Workbench provides a Jupyter-like interface where you can create and run notebooks, access data, and interact with the deployed models.
