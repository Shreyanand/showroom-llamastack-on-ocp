= LlamaStack on OpenShift

== Welcome to the LlamaStack on OpenShift Workshop

This workshop will guide you through using LlamaStack, a powerful framework for building AI applications, running on Red Hat OpenShift AI. You'll learn how to leverage various capabilities from simple Retrieval-Augmented Generation (RAG) to complex agentic systems that can interact with your environment.

== Workshop Structure

The workshop is organized into progressive levels, each building on the concepts of the previous ones:

1. **Getting Started with Llama Stack** - Introduction to OpenShift AI, LlamaStack, and vLLM
2. **Level 1: Simple RAG** - Basic retrieval and knowledge base interaction
3. **Level 2: Simple Agent with Web Search** - Extending beyond internal knowledge
4. **Level 3: Advanced Agentic with Prompt Chaining & ReAct** - Sophisticated reasoning and action patterns
5. **Level 4: Agentic RAG** - Smart integration of retrieval capabilities
6. **Level 5: Agentic and MCP** - Interaction with OpenShift and communication services
7. **Level 6: Agentic MCP and RAG** - Complete integration of all capabilities

== Lab Environment

The lab environment is pre-configured with all necessary components, including:

* Red Hat OpenShift Container Platform
* OpenShift AI (formerly RHODS)
* GPU-enabled nodes for model inference
* Pre-loaded LLM models
* JupyterLab workbench environment

Start with the first module to begin exploring the capabilities of LlamaStack on OpenShift!
